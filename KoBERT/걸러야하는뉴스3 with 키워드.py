import pandas as pd
import os
import chardet
import MeCab
from tqdm import tqdm
from itertools import combinations

# -----------------------
# íŒŒì¼ ë¡œë”© í•¨ìˆ˜
# -----------------------
def read_csv_with_encoding(csv_file):
    with open(csv_file, 'rb') as f:
        result = chardet.detect(f.read(10000))
    return pd.read_csv(csv_file, encoding=result['encoding'])

# -----------------------
# ëª…ì‚¬ ì¶”ì¶œ í•¨ìˆ˜ (MeCab ì‚¬ìš©)
# -----------------------
tagger = MeCab.Tagger()

def extract_nouns(text, min_len=2):
    if not isinstance(text, str):
        return []
    parsed = tagger.parse(text)
    nouns = []
    for line in parsed.splitlines():
        if line == 'EOS':
            break
        try:
            word, features = line.split('\t')
            pos = features.split(',')[0]
            if pos in ['NNG', 'NNP'] and len(word) >= min_len:
                nouns.append(word)
        except ValueError:
            continue
    return sorted(set(nouns))

# -----------------------
# í‚¤ì›Œë“œ 3ê°œ ì¡°í•© ë§¤ì¹­ í•¨ìˆ˜
# -----------------------
def get_matched_keyword_triplets(text, valid_triplets_set, min_len=2):
    nouns = extract_nouns(text, min_len)
    matched_triplets = []
    for triplet in combinations(nouns, 3):
        if triplet in valid_triplets_set:
            matched_triplets.append(triplet)
    return matched_triplets

# -----------------------
# ì‹¤í–‰ í•¨ìˆ˜ (íŒŒì¼ë³„ë¡œ ê²°ê³¼ë¥¼ ì €ì¥)
# -----------------------
def collect_articles_with_keyword_triplets(triplet_csv_path, article_folder_path):
    # ì²« ë²ˆì§¸ ì½”ë“œì˜ ì¶œë ¥ íŒŒì¼ (keyword_triplet_stats.csv)ì„ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì§‘
    triplet_df = pd.read_csv(triplet_csv_path)
    keyword_triplets = set(zip(triplet_df['keyword1'], triplet_df['keyword2'], triplet_df['keyword3']))
    
    # ì˜ˆì‹œë¡œ 2019ë…„ë¶€í„° 2025ë…„ê¹Œì§€ì˜ ê¸°ì‚¬ë¥¼ ì²˜ë¦¬
    for year in range(2019, 2026):
        input_file = os.path.join(article_folder_path, f"005930_{year}_processed.csv")
        print(f"\nğŸ“‚ ì²˜ë¦¬ ì¤‘: {input_file}")
        if not os.path.exists(input_file):
            print(f"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_file}")
            continue

        df = read_csv_with_encoding(input_file)

        # 'body' ì»¬ëŸ¼ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
        body_column_name = next((col for col in df.columns if col.lower() == 'body'), None)
        if not body_column_name:
            print(f"âš ï¸ 'body' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì œ ì»¬ëŸ¼ë“¤: {df.columns}")
            continue

        collected_articles = []
        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f"{year} ê¸°ì‚¬ í•„í„°ë§"):
            body = row[body_column_name]
            matched_triplets = get_matched_keyword_triplets(body, keyword_triplets)
            if matched_triplets:
                row_dict = row.to_dict()
                row_dict['matched_keyword_triplets'] = str(matched_triplets)
                collected_articles.append(row_dict)

        if collected_articles:
            result_df = pd.DataFrame(collected_articles)
            # ì…ë ¥ íŒŒì¼ ì´ë¦„ ì•ì— 'collected_with_keyword_' ë¥¼ ì¶”ê°€í•˜ì—¬ ì €ì¥
            base_name = os.path.basename(input_file)
            output_file = os.path.join(article_folder_path, f"collected_with_keyword_{base_name}")
            result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"\nâœ… ê´€ë ¨ ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ: {output_file}")
        else:
            print(f"âŒ {year}ë…„ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ì‹¤í–‰ ì˜ˆì‹œ
triplet_csv_path = "3keywords.csv"  # ì²« ë²ˆì§¸ ì½”ë“œì˜ ì¶œë ¥ íŒŒì¼
article_folder_path = "/home/kororu/KoBERT"

collect_articles_with_keyword_triplets(triplet_csv_path, article_folder_path)
