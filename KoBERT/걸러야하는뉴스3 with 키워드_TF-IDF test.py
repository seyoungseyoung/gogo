import os
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from tqdm import tqdm

# ---------------------------
# ì„¤ì •
# ---------------------------
article_folder_path = "/home/kororu/KoBERT"
top_percentiles_to_test = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30]

# ---------------------------
# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------------
collected_files = [f for f in os.listdir(article_folder_path)
                   if f.startswith("collected_with_keyword_") and f.endswith(".csv")]

all_articles = []

for file in tqdm(collected_files, desc="íŒŒì¼ ì½ëŠ” ì¤‘"):
    path = os.path.join(article_folder_path, file)
    df = pd.read_csv(path)
    if 'Body' in df.columns and not df.empty:
        df = df[['Body', 'matched_keyword_triplets']].copy()
        df['source_file'] = file
        all_articles.append(df)
    else:
        print(f"âš ï¸ '{file}' íŒŒì¼ì— 'Body' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

if not all_articles:
    raise ValueError("ðŸš¨ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

all_articles_df = pd.concat(all_articles, ignore_index=True)

# ---------------------------
# TF-IDF ê³„ì‚°
# ---------------------------
vectorizer = TfidfVectorizer(max_features=1000, stop_words=[
    'ê²ƒ', 'ìˆ˜', 'ë“±', 'ì´í›„', 'ê´€ë ¨', 'ìœ„í•´', 'ëŒ€í•´', 'í†µí•´', 'ëŒ€í•œ',
    'ê¸°ìž', 'ë³´ë„', 'ìžˆë‹¤', 'ì´ë²ˆ', 'í–ˆë‹¤', 'í–ˆë‹¤ë©°'
])
tfidf_matrix = vectorizer.fit_transform(all_articles_df['Body'].fillna(''))
scores = tfidf_matrix.sum(axis=1).A1
all_articles_df['tfidf_score'] = scores

# ---------------------------
# ê¸°ì¤€ë³„ ì»¤íŠ¸ë¼ì¸ ê·¼ì²˜ ê¸°ì‚¬ ì¶œë ¥
# ---------------------------
print("\n\n===== TF-IDF ê¸°ì¤€ë³„ ì»¤íŠ¸ë¼ì¸ ë‰´ìŠ¤ ì˜ˆì‹œ =====\n")

for p in top_percentiles_to_test:
    threshold = pd.Series(scores).quantile(p)
    
    # ì»¤íŠ¸ë¼ì¸ ê·¼ì²˜ ê¸°ì‚¬ë§Œ ì„ íƒ (Â±0.05 margin)
    margin = 0.05
    lower_bound = threshold - margin
    upper_bound = threshold + margin
    near_threshold_df = all_articles_df[
        (all_articles_df['tfidf_score'] >= lower_bound) &
        (all_articles_df['tfidf_score'] <= upper_bound)
    ].sort_values(by='tfidf_score')

    print(f"[Top {int(p * 100)}% ê¸°ì¤€]")
    print(f"- ì»¤íŠ¸ë¼ì¸: {threshold:.4f}")
    print(f"- ì»¤íŠ¸ë¼ì¸ ê·¼ì²˜ ê¸°ì‚¬ ìˆ˜: {len(near_threshold_df)}")
    print("- ëŒ€í‘œ ê¸°ì‚¬ 2ê°œ (50ìž ë¯¸ë¦¬ë³´ê¸°):")

    for i, row in enumerate(near_threshold_df.head(2).itertuples(), 1):
        body = row.Body[:50].strip().replace('\n', ' ')
        print(f"  ({i}) {body}...")

    print("-" * 50)

    # ì €ìž¥ í•„ìš” ì‹œ ì£¼ì„ í•´ì œ
    # output_file = os.path.join(article_folder_path, f"tfidf_cutline_{int(p * 100)}.csv")
    # near_threshold_df.to_csv(output_file, index=False, encoding='utf-8-sig')

print("âœ… ì»¤íŠ¸ë¼ì¸ ë¹„êµ ì™„ë£Œ.")
