import pandas as pd
from collections import Counter
from konlpy.tag import Okt
from tqdm import tqdm
import chardet
from itertools import combinations

# -----------------------
# íŒŒì¼ ë¡œë”© í•¨ìˆ˜
# -----------------------
def read_csv_with_encoding(csv_file):
    with open(csv_file, 'rb') as f:
        result = chardet.detect(f.read(10000))
    return pd.read_csv(csv_file, encoding=result['encoding'])

# -----------------------
# í‚¤ì›Œë“œ ì¡°í•© ì¶”ì¶œ í•¨ìˆ˜
# -----------------------
def extract_keyword_pairs(texts, tokenizer, min_len=2):
    pair_list = []
    for text in tqdm(texts, desc="í‚¤ì›Œë“œ ìŒ ì¶”ì¶œ ì¤‘"):
        if not isinstance(text, str):
            continue
        nouns = tokenizer.nouns(text)
        filtered = [word for word in nouns if len(word) >= min_len]
        pairs = combinations(sorted(set(filtered)), 2)
        pair_list.extend(pairs)
    return pair_list

# -----------------------
# ì£¼ìš” ì‹¤í–‰ ë¡œì§
# -----------------------
def analyze_keyword_pairs(csv_path):
    df = read_csv_with_encoding(csv_path)

    okt = Okt()

    # ìš”ì•½ ìˆìŒ / ì—†ìŒ ë‚˜ëˆ„ê¸°
    with_summary = df[df['summary'].notnull() & (df['summary'].str.strip() != '')]['body'].dropna()
    without_summary = df[df['summary'].isnull() | (df['summary'].str.strip() == '')]['body'].dropna()

    print(f"ìš”ì•½ ìˆìŒ ê¸°ì‚¬ ìˆ˜: {len(with_summary)}")
    print(f"ìš”ì•½ ì—†ìŒ ê¸°ì‚¬ ìˆ˜: {len(without_summary)}")

    # í‚¤ì›Œë“œ ìŒ ì¶”ì¶œ
    with_pairs = extract_keyword_pairs(with_summary, okt)
    without_pairs = extract_keyword_pairs(without_summary, okt)

    with_counter = Counter(with_pairs)
    without_counter = Counter(without_pairs)

    # ëª¨ë“  í‚¤ì›Œë“œ ìŒì— ëŒ€í•´ ë¹„êµ
    full_pair_stats = []
    for pair, without_count in without_counter.items():
        with_count = with_counter.get(pair, 0)
        if with_count == 0 and without_count >= 3:
            full_pair_stats.append({
                "keyword1": pair[0],
                "keyword2": pair[1],
                "without_summary_count": without_count,
                "with_summary_count": with_count,
                "frequency_gap": without_count - with_count
            })

    # ì •ë ¬
    full_pair_stats = sorted(full_pair_stats, key=lambda x: x["without_summary_count"], reverse=True)

    print("\nğŸ§© ìš”ì•½ ì—†ìŒ ë‰´ìŠ¤ì—ë§Œ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œ ì¡°í•© Top 30:")
    for item in full_pair_stats[:30]:
        print(f"{item['keyword1']}, {item['keyword2']}: {item['without_summary_count']}")

    # ì €ì¥
    df_result = pd.DataFrame(full_pair_stats)
    df_result.to_csv("keyword_pair_stats.csv", index=False)
    print("\nğŸ“ ê²°ê³¼ ì €ì¥ë¨ â†’ keyword_pair_stats.csv")

# ì˜ˆì‹œ ì‹¤í–‰
csv_path = "/home/kororu/KoBERT/articles_summary24.csv"  # â† ë„¤ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •
analyze_keyword_pairs(csv_path)
